# Smart Document Router (SDR)

## Problem Statement

Businesses are flooded with documents like invoices, receipts, and contracts that require manual classification, data extraction, and routing. Even when these workflows are digitized, most organizations still lack effective tools to search, retrieve, and interact with the underlying data. As a result, finding the right informationâ€”like the status of an invoice or a payment dateâ€”remains slow, error-prone, and operationally expensive.

## Solution

A fully automated, serverless pipeline leveraging AWS Lambda and Amazon Bedrock to classify, extract, and route documents efficiently.

## Architecture Overview

```
[User Document Upload â†’ Lambda: UploadHandler (Function URL)]
        â†“
[S3 Incoming Bucket (ObjectCreated Event)]
        â†“
[Lambda: DocumentClassifier]
  â””â”€ Amazon Bedrock Classification
        â†“
[Lambda: DocumentDataExtractor]
  â””â”€ Extract Data (Bedrock/Textract)
        â†“
[Lambda: EmbeddingGenerator]
  â””â”€ Generate Embeddings (Bedrock Titan)
        â†“
[PostgreSQL (pgvector)]
  â””â”€ Store Document Embeddings
        â†“
[Lambda: DocumentRouter]
 â”œâ”€ Store Metadata (DynamoDB)
 â”œâ”€ Move File (S3 Organized Folder)
 â””â”€ Send Notifications (SNS/SES)

[User Query â†’ API Gateway + Lambda: ChatQueryHandler]
  â”œâ”€ Generate Query Embedding (Bedrock Titan)
  â”œâ”€ Query PostgreSQL for similar document chunks
  â”œâ”€ Construct Prompt with relevant chunks
  â””â”€ Generate Answer (Bedrock)
```

## Lambda Functions Explained

| Lambda Function   | Responsibility                                  |
| ----------------- | ----------------------------------------------- |
| **UploadHandler** | Handles document uploads via a Function URL and stores them in the incoming S3 bucket. |

| **DocumentClassifier**    | Classifies document type using Amazon Bedrock.        |
| ------------------------- | ----------------------------------------------------- |
| **DocumentDataExtractor** | Extracts structured data from documents.              |
| **EmbeddingGenerator**    | Generates vector embeddings from document text and stores them in PostgreSQL. |
| **DocumentRouter**        | Routes files, logs metadata, and sends notifications. |
| **ChatQueryHandler**      | Handles user queries, retrieves relevant document chunks, and generates answers. |


### Classification

```
Document types: ["invoice", "receipt", "contract", "report", "other"]
Classify this document clearly into one type:

Document Content:
<<DOCUMENT_TEXT>>
```

### Extraction

```
Extract fields: ["vendor_name", "invoice_number", "total_amount", "due_date"] from the document below as structured JSON.

Document:
<<DOCUMENT_TEXT>>
```

## ðŸš€ Deployment

This project is deployed using the AWS CDK. The following steps outline the deployment process:

### 1. Prerequisites

*   Node.js and npm installed
*   AWS CLI configured with your credentials
*   AWS CDK installed (`npm install -g aws-cdk`)

### 2. Install Dependencies

Navigate to the `cdk` directory and install the required npm packages:

```bash
cd cdk
npm install
```

### 3. Deploy the Stacks

The CDK application is divided into multiple stacks. Deploy them in the following order:

```bash
cdk deploy SdrBucketsStack
cdk deploy SdrDatabaseStack
cdk deploy SdrPostgresStack
cdk deploy SdrChatStack
cdk deploy SdrLambdasStack
```

### 4. Enable pgvector Extension

After deploying the `SdrPostgresStack`, you need to manually enable the `pgvector` extension in the PostgreSQL database if this is not present by default. A Makefile command is provided for this purpose:

```bash
make enable-pgvector
```

This command invokes a Lambda function that connects to the database and executes the necessary SQL command.

## Document dataset

This project contains a dataset of 2,677 PDF files, each representing a unique company document. These documents are derived from the Northwind dataset, which is commonly used for demonstrating database functionalities. 

The dataset was downloaded from public project at Kaggle https://www.kaggle.com/datasets/ayoubcherguelaine/company-documents-dataset?resource=download.

## Document Upload

Documents can be uploaded to the system via the `UploadHandler` Lambda's Function URL. This URL is exposed as a CloudFormation output.

**Upload Command Example (using `curl`):**

```bash
curl -X POST -H "x-file-name: your_document_name.pdf" --data-binary "@./path/to/your_document.pdf" <YOUR_UPLOAD_FUNCTION_URL>/upload
```

Replace `<YOUR_UPLOAD_FUNCTION_URL>` with the actual URL from your CloudFormation stack outputs (e.g., `aws cloudformation describe-stacks --stack-name SdrLambdasStack --query 'Stacks[0].Outputs[?OutputKey==`UploadUrl`].OutputValue' --output text`).

## ðŸ§ª Testing with Make

To simplify testing, a `Makefile` is provided with the following commands:

*   `make enable-pgvector`: Manually invokes the Lambda function to enable the `pgvector` extension in your PostgreSQL database. This needs to be run once after the `SdrPostgresStack` is deployed.

*   `make test`: Uploads a sample document, waits for processing, and then queries the chat API with a predefined question. You can override the default `UPLOAD_FILE` and `CHAT_QUERY` variables.

    ```bash
    make test UPLOAD_FILE=data/CompanyDocuments/invoices/invoice_10249.pdf CHAT_QUERY="What is the total amount of the invoice?"
    ```

*   `make chat`: Directly queries the chat API with a predefined or overridden question. Useful for quick iterations on chat prompts.

    ```bash
    make chat CHAT_QUERY="What is the order ID for the invoice from Karin Josephs?"
    ```

    Or

    ```bash
    make chat CHAT_QUERY="What do you know about 10249?"
    ```


## Chat with your document

After a document has been uploaded and processed (which includes embedding generation), you can chat with it using the exposed API Gateway endpoint.

**Chat Command Example (using `curl`):**

```bash
curl -X POST -H "Content-Type: application/json" -d '{"query": "What is the total amount of invoice INV-2321?"}' <YOUR_CHAT_API_URL>/chat
```

Replace `<YOUR_CHAT_API_URL>` with the actual URL from your CloudFormation stack outputs (e.g., `aws cloudformation describe-stacks --stack-name SdrChatStack --query 'Stacks[0].Outputs[?OutputKey==`ChatApiUrl`].OutputValue' --output text`).

## ðŸ“¦ Example Data Flow JSON

```json
{
  "document_type": "invoice",
  "fields": {
    "vendor_name": "ACME Corp.",
    "invoice_number": "INV-2321",
    "total_amount": "USD 1,245.00",
    "due_date": "2025-07-20"
  },
  "original_s3_path": "uploads/incoming/doc123.pdf",
  "routed_s3_path": "organized/invoices/doc123.pdf",
  "timestamp": "2025-06-28T12:00:00Z"
}
```

## ðŸ”” Notifications and Routing

**S3 Folder Structure:**

```
s3://company-documents/
â”œâ”€â”€ organized/
â”‚   â”œâ”€â”€ invoices/
â”‚   â”œâ”€â”€ contracts/
â”‚   â”œâ”€â”€ receipts/
â”‚   â””â”€â”€ other/
â””â”€â”€ uploads/
    â””â”€â”€ incoming/
```

**Notifications:**

- Email to Accounting for invoices
- Email to Legal for contracts

## Implementation Roadmap

### Step 1: AWS Resources Setup

- S3 buckets for documents
- DynamoDB table for metadata
- SNS/SES for alerts

### Step 2: Lambda Development

- Develop classification, extraction, and routing Lambdas

### Step 3: Integration and Testing

- Validate classification and extraction accuracy
- Ensure correct routing and alerts

### Step 4: Monitoring

- Set up CloudWatch alarms
- Automate periodic summaries

## Security Best Practices

- Minimal IAM permissions
- Encryption at rest/in-transit
- Audit trails (CloudTrail, DynamoDB logs)

## Cost Estimation (Monthly \~5,000 documents)

> Costs are approximated.

| Service                | Estimated Monthly Cost |
| ---------------------- | ---------------------- |
| Lambda                 | \$1.00                 |
| S3 Storage/Requests    | \$2.00                 |
| Bedrock (Claude/Titan) | \$25.00                |
| DynamoDB               | \$1.00                 |
| PostgreSQL             | \$10.00                |
| SNS/SES Notifications  | \$1.00                 |
| **Total**              | **\~\$40/month**       |


## Demo Submission Outline

pending

### GitHub Repository Structure

```
smart-document-router/
â”œâ”€â”€ README.md
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ classifier/
â”‚   â”œâ”€â”€ extractor/
â”‚   â””â”€â”€ router/
â”œâ”€â”€ tests/
```

---

**Next Steps**

- Develop comprehensive tests
- Fine-tune Bedrock prompts for maximum accuracy